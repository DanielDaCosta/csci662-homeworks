{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import random\n",
    "import argparse\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(example):\n",
    "    \n",
    "    ################################\n",
    "    ##### YOUR CODE BEGINGS HERE ###\n",
    "    \n",
    "    # Design and implement the transformation as mentioned in pdf\n",
    "    # You are free to implement any transformation but the comments at the top roughly describe\n",
    "    # how you could implement two of them --- synonym replacement and typos.\n",
    "    \n",
    "    # You should update example[\"text\"] using your transformation\n",
    "        \n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    ##### YOUR CODE ENDS HERE ######\n",
    "    \n",
    "    return example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the dataset is saved\n",
    "load_directory = \"dataset/\"\n",
    "\n",
    "# Load the dataset from the specified directory\n",
    "loaded_data = load_from_disk(load_directory)\n",
    "\n",
    "# Now you can access the individual splits (train, test, unsupervised) as follows:\n",
    "train_dataset = loaded_data[\"train\"]\n",
    "test_dataset = loaded_data[\"test\"]\n",
    "unsupervised_dataset = loaded_data[\"unsupervised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacement probability\n",
    "probability = 0.6\n",
    "\n",
    "# Generate a random number between 0 and 1\n",
    "random_number = random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list  = word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_word = random.choice(word_list)\n",
    "synonyms = wn.synsets(chosen_word)\n",
    "\n",
    "# If chosen word doesn't have a synonym select retry until finding a word that does.\n",
    "max_retry = len(word_list)\n",
    "retry = 0 \n",
    "while (len(synonyms) == 0 and retry <= max_retry):\n",
    "    chosen_word = random.choice(word_list)\n",
    "    synonyms = wn.synsets(chosen_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform POS tagging\n",
    "pos_tags = pos_tag(word_list)\n",
    "\n",
    "# Print the word and its POS tag\n",
    "chosen_word_tag = {tag for word, tag in pos_tags if word == chosen_word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None  # If no match is found, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_list = set()\n",
    "for syn in synonyms: # ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
    "    for lemma in syn.lemmas():\n",
    "        if lemma.name() != chosen_word:\n",
    "            synonym_list.add(lemma.name().replace('_', ' ')) # Replace underscores for multi-word synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accept',\n",
       " 'acquire',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'aim',\n",
       " 'ask',\n",
       " 'assume',\n",
       " 'bring',\n",
       " 'call for',\n",
       " 'carry',\n",
       " 'charter',\n",
       " 'choose',\n",
       " 'claim',\n",
       " 'conduct',\n",
       " 'consider',\n",
       " 'consume',\n",
       " 'contain',\n",
       " 'contract',\n",
       " 'convey',\n",
       " 'deal',\n",
       " 'demand',\n",
       " 'direct',\n",
       " 'drive',\n",
       " 'engage',\n",
       " 'exact',\n",
       " 'fill',\n",
       " 'film',\n",
       " 'get',\n",
       " 'get hold of',\n",
       " 'guide',\n",
       " 'have',\n",
       " 'hire',\n",
       " 'hold',\n",
       " 'ingest',\n",
       " 'involve',\n",
       " 'issue',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'lease',\n",
       " 'look at',\n",
       " 'make',\n",
       " 'necessitate',\n",
       " 'need',\n",
       " 'occupy',\n",
       " 'pack',\n",
       " 'payoff',\n",
       " 'pick out',\n",
       " 'postulate',\n",
       " 'proceeds',\n",
       " 'read',\n",
       " 'remove',\n",
       " 'rent',\n",
       " 'require',\n",
       " 'return',\n",
       " 'select',\n",
       " 'shoot',\n",
       " 'strike',\n",
       " 'study',\n",
       " 'submit',\n",
       " 'subscribe',\n",
       " 'subscribe to',\n",
       " 'take aim',\n",
       " 'take away',\n",
       " 'take in',\n",
       " 'take on',\n",
       " 'take up',\n",
       " 'takings',\n",
       " 'train',\n",
       " 'use up',\n",
       " 'withdraw',\n",
       " 'yield'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
